---
content_type: page
description: Social and Ethical Responsibilities of Computing (SERC) topics focusing
  on inequality, justice, and human rights. Includes class resources, MIT case studies,
  and active learning projects.
draft: false
learning_resource_types: []
ocw_type: SupplementalResourceSection
title: Inequality, Justice, & Human Rights
uid: 8918d065-a83d-28bb-930c-c997c41daa24
video_metadata:
  youtube_id: null
---
## {{% resource_link "b50f80a0-1b37-7c22-394d-94da1312c4ac" "STS.047 Quantifying People: A History of Social Science" %}}

*Author:* Will Deringer

*Lecture module:* “Quantify and Punish: Data, Race, and Policing from the Burgess Method to Big Data”

*Keywords:* ​​policing; criminal justice; race; racism; actuarial techniques; risk assessments; big data; surveillance

*Questions addressed:*

- What role have quantitative data, computational methods, and social science played in the construction of modern systems of criminal justice?
- How has quantification contributed to the injustices of modern policing and punishment—to the creation and maintenance of a system that disproportionately and unjustly targets, punishes, incarcerates, and kills people of color, especially Black citizens?
- What can history tell us about the role that data and computation should—or should not—play in efforts to create a more just system of justice in the future?

## {{% resource_link "1232f891-70b9-433b-b458-96ecfeaae254" "17.806 Quantitative Research Methods IV: Advanced Topics" %}}

*Author:* In Song Kim

*Lecture Module:* “Analyzing the Impact of Police Stopping in Political Behavior” 

*Keywords:* policing, stop-question-and-frisk, racial minorities, political behavior 

*Module Goals:* This problem set explores how/whether policing against citizens and against racial minorities affects political behavior by leveraging a variety of data sources available online, including micro-level administrative data on policing. 

## {{% resource_link "58ebf2bb-b22e-418b-a6ea-6934c70d99ec" "Considered Design Cards" %}}

*Authors:* Mikaela Springsteen, Madhurima Das, Swati Gupta

The activities which these cards contain are designed to subvert expectations and elicit conversation regarding the social and ethical responsibilities associated with design. They are organized into five categories: inputs, processes, outputs, feedback loops, and ecosystems, each of which focuses on a different part of the design or product lifecycle. 

These cards are intended to help foster in users a creative and flexible approach to the potential impacts of a design process, rather than treating any such outcomes or impacts as a formulaic "check-box" aspect of design. Indeed, flexibility is built into the very nature of the cards themselves—these cards can be used in a variety of settings, and while the cards may have specific time and material requirements listed, they can often be adapted and ‘remixed’ to suit specific learning environments and contexts.                  

## MIT Case Studies in Social and Ethical Responsibilities of Computing

Brief, specially commissioned and peer-reviewed cases intended to be effective for undergraduate instruction across a range of classes and fields of study. Some cases are paired with active learning projects developed by students at MIT and reviewed by faculty and senior researchers.

### Summer 2023

{{% resource_link "0aee2633-de58-4efa-86a4-986ca2a1592e" "**Pretrial Risk Assessment on the Ground: Algorithms, Judgments, Meaning, and Policy**" %}}**, by Cristopher Moore, Elise Ferguson, and Paul Guerin**

*Keywords:* risk assessment, pretrial detention, algorithmic fairness, criminal justice reform

### Winter 2023

{{% resource_link "55153b24-dddd-438b-8323-e587eaededb3" "**Algorithmic Fairness in Chest X-ray Diagnosis: A Case Study**" %}}**, by Haoran Zhang, Thomas Hartvigsen, and Marzyeh Ghassemi (MIT)**

*Keywords:* algorithmic fairness, deep learning, medical imaging, machine learning for health care

{{% resource_link "f8222bea-083c-4f5f-93e2-40689fc9ac15" "**The Right to Be an Exception to a Data-Driven Rule**" %}}**, by Sarah H. Cen and Manish Raghavan (MIT)**

*Keywords*: data-driven decision-making, rights and duties, individualization, uncertainty, harm

### Summer 2022

{{% resource_link "9edb8c8d-9cd8-44ac-97c2-7d35368b3c5e" "**\"Porsche Girl\": When a Dead Body Becomes a Meme**" %}}**, by Nadia de Vries (University of Amsterdam)**

*Keywords*: digital death, bodies, memes, online abuse, Nikki Castouras

{{% resource_link "8b6d79e4-326e-4375-960b-9f8273ea6f4f" "**Patenting Bias: Algorithmic Race and Ethnicity Classifications, Proprietary Rights, and Public Data**" %}}**, by Tiffany Nichols (Harvard University)**

*Keywords*: racial and ethnic classifications, algorithmic bias, patents, public data

### Winter 2022

{{% resource_link "6ca156bf-380f-4b96-99c2-58069b9071c5" "**Protections for Human Subjects in Research: Old Models, New Needs?**" %}}**, by Laura Stark (Vanderbilt University)**

*Keywords:* human-subjects research, informed consent, institutional review boards, big data

{{% resource_link "179b9622-183d-4d43-98de-3a86f998985f" "**Algorithmic Redistricting and Black Representation in US Elections**" %}}**, by Zachary Schutzman (MIT)**

*Keywords:* redistricting, algorithms, race, politics, elections

### Summer 2021

{{% resource_link "7a377b13-007a-4d18-b3b2-fd9363c3f8bf" "**Hacking Technology, Hacking Communities: Codes of Conduct and Community Standards in Open Source**" %}}**, by Christina Dunbar-Hester (University of Southern California)**

*Keywords:* open source software; diversity and inclusion; community governance; gender; race; values in computing; codes of conduct

### Winter 2021

{{% resource_link "c6c31aa5-cf1a-4362-a09f-4b7363177138" "**The Dangers of Risk Prediction in the Criminal Justice System**" %}}**, by Julia Dressel (Dartmouth College) and Hany Farid (University of California, Berkeley)**

*Keywords:* algorithmic risk prediction, algorithmic bias, algorithmic fairness, algorithmic transparency, criminal justice

{{% resource_link "f453bf58-3954-4c5b-8df8-3a6544a8ed25" "**The Bias in the Machine: Facial Recognition Technology and Racial Disparities**" %}}**, by Sidney Perkowitz (Emory University)**

*Keywords:* facial recognition, justice system, racial equity, false arrest

{{% resource_link "4e2e981e-abf7-495a-9092-0c9a9bc2b0c4" "**Who Collects the Data? A Tale of Three Maps**" %}}**, by Catherine D'Ignazio (MIT) and Lauren Klein (Emory University)**

*Keywords:* redlining, social inequality and oppression, missing data, counterdata, matrix of domination, who questions

## Active Learning Projects Developed at MIT

### {{% resource_link "17714235-e1c6-4242-08f5-db881ee8643e" "Active Learning Project: Active Learning Project on Developing Codes on Conduct (PDF)" %}}{{% resource_link "0ddc2160-f045-ce3f-896d-53ad99980c2a" "(DOCX)" %}}

An exercise in developing a code of conduct for a team-based course in Github-hosted project repositories. 

- *Associated case study:* Dunbar-Hester, C. (2021). "Hacking Technology, Hacking Communities: Codes of Conduct and Community Standards in Open Source." MIT Case Studies in Social and Ethical Responsibilities of Computing, Summer 2021. {{% resource_link "f1e773b7-7584-4425-80a9-10efdf65873f" "https://doi.org/10.21428/2c646de5.07bc6308" %}}