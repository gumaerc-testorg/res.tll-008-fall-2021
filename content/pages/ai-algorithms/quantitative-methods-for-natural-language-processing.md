---
content_type: page
learning_resource_types: []
ocw_type: SupplementalResourceSection
parent_title: AI and Algorithms
parent_type: SupplementalResourceSection
parent_uid: 17e1fff5-e25b-6a04-922e-1cd9935bbd5a
title: '6.864 Quantitative Methods for Natural Language Processing '
uid: e973e803-f498-7fee-0427-c3ab9df01ebf
---

_\> Related Topics:_ [AI and Algorithms]({{< baseurl >}}/pages/ai-algorithms), [Ethical Computing and Practice]({{< baseurl >}}/pages/ethical-computing-and-practice)

_Authors:_ Jacob Andreas, Catherine D'Ignazio, Harini Suresh

_Keywords:_ data annotation; natural language processing; machine learning; content moderation

_Topics addressed:_

*   Critically question how and by whom the data was created
*   Determine what its limitations might be
*   Discuss what the data should and should not be used for

Resources:
----------

### [Assignment “Dataset Creation” Description (PDF)]({{< baseurl >}}/resources/mitres-tll008f21-6864hw2-1) ([DOCX]({{< baseurl >}}/resources/mitres-tll008f21-6864hw2))

_Part 0:_ Short-answer reflections to a few hypothetical scenarios.

*   [Dataset Creation Part 0 (PDF)]({{< baseurl >}}/resources/mitres-tll008f21_6864pt0) ([DOCX]({{< baseurl >}}/resources/mitres-tll008f21_6864pt0-1)) 

_Part 1:_ This part is done in groups. You will have the role of a researcher in charge of creating a dataset. You’ll receive a hypothetical task, make decisions about what labels you want to collect, and write instructions to a group of annotators.

*   [Dataset Creation Part 1 (PDF)]({{< baseurl >}}/resources/mitres-tll008f21-6864pt1) ([DOCX]({{< baseurl >}}/resources/mitres-tll008f21-6864pt1-1))
    *   [Task A: Comment Moderation (PDF)]({{< baseurl >}}/resources/mitres-tll008f21-6864taska) ([DOCX]({{< baseurl >}}/resources/mitres-tll008f21-6864taska-1))
    *   [Task B: Credibility Evaluation (PDF)]({{< baseurl >}}/resources/mitres-tll008f21-6864taskb) ([DOCX]({{< baseurl >}}/resources/mitres-tll008f21-6864taskb-1))

_Part 2:_ This part is done individually. You’ll now be an annotator. First, take the instructions you wrote and annotate a new set of examples according to them. Then, you will receive instructions from a different group, for a different task, and will be asked to annotate a set of examples by following their instructions.

*   [Dataset Creation Part 2A (PDF)]({{< baseurl >}}/resources/mitres-tll008f21-6864pt2a) ([DOCX]({{< baseurl >}}/resources/mitres-tll008f21-6864pt2a-1))
*   [Dataset Creation Part 2B (PDF)]({{< baseurl >}}/resources/mitres-tll008f21-6864pt2b) ([DOCX]({{< baseurl >}}/resources/mitres-tll008f21-6864pt2b-1))

_Part 3:_ Pick one of the listed readings to read & respond to. See assignment description for titles.

Additional Reading:
-------------------

Paullada, Amandalynne, Inioluwa Deborah Raji, et al. "[Data and Its (Dis) Contents: A Survey of Dataset Development and Use in Machine Learning Sesearch](https://arxiv.org/abs/2012.05345)." arXiv preprint arXiv:2012.05345 (2020).

D'Ignazio, Catherine and Lauren Klein. "[What Gets Counted Counts](https://data-feminism.mitpress.mit.edu/pub/h1w0nbqp/release/3)." Chapter 4 in _Data Feminism_. March 16, 2020. 

Gebru, Timnit, Jamie Morgenstern, et al. "[Datasheets for datasets (PDF - 2.1MB)](https://arxiv.org/pdf/1803.09010.pdf)." arXiv preprint arXiv:1803.09010 (2018).

Bhuiyan, M. Momen, Amy X. Zhang, Connie Moon Sehat, and Tanushree Mitra. "[Investigating Differences in Crowdsourced News Credibility Assessment: Raters, Tasks, and Expert Criteria (PDF)](https://assets.ctfassets.net/tlowcqj4pb76/3TXIYQf54lxMF8ylLqyPuE/ad0222fd424eac7d1764a404a68f9212/Investigating_Differences_in_Crowdsourced_News_Credibility_Assessment_Raters_Tasks_and_Expert_Criteria.pdf)." _Proceedings of the ACM on Human-Computer Interaction_ 4, no. CSCW2 (2020): 1-26.

Metz, Cade. "[A.I. is Learning From Humans. Many Humans](https://www.nytimes.com/2019/08/16/technology/ai-humans.html)." _The New York Times_. Aug. 16, 2019.

Kaye, Kate. "[These Companies Claim to Provide 'Fair-Trade' Data Work. Do They?](https://www.technologyreview.com/2019/08/07/133845/cloudfactory-ddd-samasource-imerit-impact-sourcing-companies-for-data-annotation/)" _Technology Review_. Aug. 7, 2019.